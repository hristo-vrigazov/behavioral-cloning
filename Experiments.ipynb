{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioural cloning project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Configure matlab to show graphics in the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change to 'data' when training on a GPU\n",
    "PATH_TO_DATA = 'all_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shape of the image\n",
    "input_shape = (66, 200, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_folder(data_folder):\n",
    "    return '{}/IMG'.format(data_folder)\n",
    "\n",
    "def path_driving_log(data_folder):\n",
    "    return '{}/driving_log.csv'.format(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets = ['train', 'test', 'valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_driving_log_dataframe(data_folder):\n",
    "    driving_log_df = pd.read_csv(path_driving_log(data_folder))\n",
    "    return driving_log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driving_log_df = get_driving_log_dataframe(PATH_TO_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_approximation = 10e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 2645\n",
      "Negative: 3477\n",
      "Neutral: 8694\n"
     ]
    }
   ],
   "source": [
    "num_positive_steerings = len(driving_log_df[driving_log_df['steering'] > zero_approximation])\n",
    "num_negative_steerings = len(driving_log_df[driving_log_df['steering'] < -zero_approximation])\n",
    "num_neutral_steerings = len(driving_log_df[abs(driving_log_df['steering']) <= zero_approximation])\n",
    "\n",
    "print('Positive: {}'.format(num_positive_steerings))\n",
    "print('Negative: {}'.format(num_negative_steerings))\n",
    "print('Neutral: {}'.format(num_neutral_steerings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_steering_weight = 10\n",
    "negative_steering_weight = num_positive_steerings * 10/ num_negative_steerings\n",
    "neutral_steering_weight = num_positive_steerings * 10 / num_neutral_steerings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_folders = dict(zip(datasets, map(lambda folder: '{0}/{1}'.format(PATH_TO_DATA, folder), datasets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 'all_data/test', 'train': 'all_data/train', 'valid': 'all_data/valid'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import imread\n",
    "from os import listdir\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import math\n",
    "\n",
    "def image_label_generator(data_folder, batch_size=64):\n",
    "    driving_log_df = get_driving_log_dataframe(data_folder)\n",
    "    number_of_examples = len(driving_log_df)\n",
    "    image_columns = ['center', 'left', 'right']\n",
    "    \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    weights = []\n",
    "    index_in_batch = 0\n",
    "    batch_number = 0\n",
    "    \n",
    "    while True:\n",
    "        for image_column in image_columns:\n",
    "            image_series = driving_log_df[image_column]\n",
    "            steering_series = driving_log_df['steering']\n",
    "            for offset in range(0, number_of_examples, batch_size):\n",
    "                X_train = []\n",
    "                y_train = []\n",
    "                weights = []\n",
    "\n",
    "                end_of_batch = min(number_of_examples, offset + batch_size)\n",
    "\n",
    "                for j in range(offset, end_of_batch):\n",
    "                    image_filename = image_series[j].lstrip().rstrip()\n",
    "                    image = Image.open('{0}/{1}'.format(data_folder, image_filename))\n",
    "                    image = np.asarray(image.resize((200, 66)))\n",
    "                    label = steering_series[j]\n",
    "                    \n",
    "#                     weights.append(1)\n",
    "                    if abs(label) < 10e-4:\n",
    "                        weights.append(neutral_steering_weight + math.exp(abs(label)))\n",
    "                    elif label > 0:\n",
    "                            weights.append(positive_steering_weight + math.exp(abs(label)))\n",
    "                    else:\n",
    "                        weights.append(negative_steering_weight + math.exp(abs(label)))\n",
    "                    \n",
    "                    \n",
    "                    X_train.append(image)\n",
    "                    y_train.append(label)\n",
    "                    X_train, y_train, weights = shuffle(X_train, y_train, weights)\n",
    "\n",
    "                yield np.array(X_train), np.array(y_train), np.array(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(3, 1, 1, \n",
    "                          input_shape=input_shape, \n",
    "                          border_mode='same', \n",
    "                          activation='relu',\n",
    "                          init='he_normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(24, \n",
    "                        5, 5,\n",
    "                       subsample=(2, 2),\n",
    "                       init='he_normal'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(36, \n",
    "                        5, 5,\n",
    "                       subsample=(2, 2),\n",
    "                       init='he_normal'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(48, \n",
    "                        5, 5,\n",
    "                       subsample=(2, 2),\n",
    "                       init='he_normal'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(64,\n",
    "                       3, 3,\n",
    "                       init='he_normal'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(64,\n",
    "                       3, 3,\n",
    "                       init='he_normal'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu', init='he_normal'))\n",
    "model.add(Dense(50, activation='relu', init='he_normal'))\n",
    "model.add(Dense(10, activation='relu', init='he_normal'))\n",
    "model.add(Dense(1, activation='linear', init='he_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 66, 200, 3)    12          convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 66, 200, 3)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 66, 200, 3)    12          dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 31, 98, 24)    1824        batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 31, 98, 24)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 31, 98, 24)    96          dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 14, 47, 36)    21636       batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 14, 47, 36)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 14, 47, 36)    144         dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 5, 22, 48)     43248       batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 5, 22, 48)     0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 5, 22, 48)     192         dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 3, 20, 64)     27712       batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 3, 20, 64)     0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 3, 20, 64)     256         dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 1, 18, 64)     36928       batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 1, 18, 64)     0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1152)          0           dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           115300      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 50)            5050        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            510         dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             11          dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 252,931\n",
      "Trainable params: 252,581\n",
      "Non-trainable params: 350\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=10e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam, \n",
    "              loss='mse',\n",
    "             metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_generator = image_label_generator(PATH_TO_DATA)\n",
    "samples = len(get_driving_log_dataframe(PATH_TO_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "14816/14816 [==============================] - 52s - loss: 0.3442 - mean_squared_error: 0.0379    \n",
      "Epoch 2/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.2844 - mean_squared_error: 0.0300    \n",
      "Epoch 3/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.2758 - mean_squared_error: 0.0297    \n",
      "Epoch 4/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.2869 - mean_squared_error: 0.0298    \n",
      "Epoch 5/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.2592 - mean_squared_error: 0.0273    \n",
      "Epoch 6/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.2214 - mean_squared_error: 0.0250    \n",
      "Epoch 7/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.2030 - mean_squared_error: 0.0231    \n",
      "Epoch 8/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.1905 - mean_squared_error: 0.0221    \n",
      "Epoch 9/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.1854 - mean_squared_error: 0.0217    \n",
      "Epoch 10/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.1741 - mean_squared_error: 0.0207    \n",
      "Epoch 11/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.1748 - mean_squared_error: 0.0208    \n",
      "Epoch 12/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.1735 - mean_squared_error: 0.0206    \n",
      "Epoch 13/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.1703 - mean_squared_error: 0.0203    \n",
      "Epoch 14/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.1716 - mean_squared_error: 0.0205    \n",
      "Epoch 15/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.1751 - mean_squared_error: 0.0208    \n",
      "Epoch 16/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.1707 - mean_squared_error: 0.0204    \n",
      "Epoch 17/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.1670 - mean_squared_error: 0.0201    \n",
      "Epoch 18/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.1721 - mean_squared_error: 0.0205    \n",
      "Epoch 19/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.1684 - mean_squared_error: 0.0202    \n",
      "Epoch 20/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.1645 - mean_squared_error: 0.0198    \n",
      "Epoch 21/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.1699 - mean_squared_error: 0.0204    \n",
      "Epoch 22/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.1661 - mean_squared_error: 0.0199    \n",
      "Epoch 23/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.1648 - mean_squared_error: 0.0198    \n",
      "Epoch 24/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.1683 - mean_squared_error: 0.0202    \n",
      "Epoch 25/25\n",
      "14816/14816 [==============================] - 48s - loss: 0.1628 - mean_squared_error: 0.0199    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89e5e2b940>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_generator = image_label_generator(PATH_TO_DATA)\n",
    "samples = len(get_driving_log_dataframe(PATH_TO_DATA))\n",
    "model.fit_generator(image_generator, \n",
    "                    samples_per_epoch=samples, \n",
    "                    nb_epoch=25,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_val, y_val, w = next(image_label_generator(PATH_TO_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24417001],\n",
       "       [-0.03308296],\n",
       "       [-0.05282918],\n",
       "       [-0.02040869],\n",
       "       [-0.07171255],\n",
       "       [-0.01176016],\n",
       "       [-0.06641157],\n",
       "       [-0.01749383],\n",
       "       [-0.05876631],\n",
       "       [-0.02088972],\n",
       "       [ 0.22061512],\n",
       "       [-0.01328376],\n",
       "       [-0.01015107],\n",
       "       [-0.02610557],\n",
       "       [-0.0138338 ],\n",
       "       [-0.02636448],\n",
       "       [-0.03744147],\n",
       "       [-0.00980639],\n",
       "       [-0.03705426],\n",
       "       [-0.01788818],\n",
       "       [-0.02097031],\n",
       "       [-0.01415297],\n",
       "       [-0.00916732],\n",
       "       [-0.01469635],\n",
       "       [-0.03988317],\n",
       "       [-0.01290986],\n",
       "       [-0.02484368],\n",
       "       [-0.02693775],\n",
       "       [-0.00648441],\n",
       "       [-0.00314726],\n",
       "       [-0.01802123],\n",
       "       [-0.06115625],\n",
       "       [ 0.17940703],\n",
       "       [-0.04470982],\n",
       "       [-0.00487347],\n",
       "       [-0.03361421],\n",
       "       [-0.06399942],\n",
       "       [-0.00702863],\n",
       "       [ 0.20953931],\n",
       "       [-0.02667213],\n",
       "       [-0.00509981],\n",
       "       [-0.0385359 ],\n",
       "       [-0.0129332 ],\n",
       "       [-0.02023245],\n",
       "       [-0.02734696],\n",
       "       [-0.02885082],\n",
       "       [-0.06242064],\n",
       "       [-0.02568535],\n",
       "       [-0.02401909],\n",
       "       [-0.05245441],\n",
       "       [ 0.22367489],\n",
       "       [-0.06586641],\n",
       "       [-0.02709663],\n",
       "       [-0.02670377],\n",
       "       [-0.00382422],\n",
       "       [-0.01398304],\n",
       "       [-0.03477243],\n",
       "       [-0.01127298],\n",
       "       [-0.04476904],\n",
       "       [-0.01232528],\n",
       "       [ 0.12131376],\n",
       "       [-0.01677823],\n",
       "       [-0.01374511],\n",
       "       [-0.04756546]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3127406 , -0.05468059,  0.        , -0.2021756 ,  0.        ,\n",
       "        0.        ,  0.        , -0.07803941, -0.3285842 , -0.2567704 ,\n",
       "        0.        ,  0.        , -0.3898351 , -0.4916646 , -0.164727  ,\n",
       "        0.        ,  0.        , -0.2008467 , -0.05077529,  0.        ,\n",
       "       -0.512769  ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.3087602 ,  0.        , -0.4662809 , -0.2275407 ,\n",
       "        0.        ,  0.        , -0.3237014 ,  0.        , -0.1233637 ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -0.06370211,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.4099739 ,  0.        ,  0.        ,  0.        , -0.357723  ,\n",
       "       -0.00134849,  0.        ,  0.        , -0.3571165 ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.3544564 , -0.1534824 ,\n",
       "       -0.6370363 ,  0.        , -0.2147133 , -1.        ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "with open('model.json', 'r') as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14816/14816 [==============================] - 50s - loss: 0.3507 - mean_squared_error: 0.0380    \n",
      "Epoch 2/10\n",
      "14816/14816 [==============================] - 48s - loss: 0.2957 - mean_squared_error: 0.0293    \n",
      "Epoch 3/10\n",
      "14816/14816 [==============================] - 48s - loss: 0.2632 - mean_squared_error: 0.0268    \n",
      "Epoch 4/10\n",
      "14816/14816 [==============================] - 48s - loss: 0.2357 - mean_squared_error: 0.0250    \n",
      "Epoch 5/10\n",
      "14816/14816 [==============================] - 48s - loss: 0.2257 - mean_squared_error: 0.0248    \n",
      "Epoch 6/10\n",
      "14816/14816 [==============================] - 48s - loss: 0.2068 - mean_squared_error: 0.0233    \n",
      "Epoch 7/10\n",
      "14816/14816 [==============================] - 48s - loss: 0.2041 - mean_squared_error: 0.0234    \n",
      "Epoch 8/10\n",
      "14816/14816 [==============================] - 48s - loss: 0.2040 - mean_squared_error: 0.0233    \n",
      "Epoch 9/10\n",
      "14816/14816 [==============================] - 48s - loss: 0.1937 - mean_squared_error: 0.0221    \n",
      "Epoch 10/10\n",
      "14816/14816 [==============================] - 48s - loss: 0.1858 - mean_squared_error: 0.0214    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f898c29a710>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.compile(optimizer=adam, \n",
    "              loss='mse',\n",
    "             metrics=['mean_squared_error'])\n",
    "\n",
    "image_generator = image_label_generator(PATH_TO_DATA)\n",
    "samples = len(get_driving_log_dataframe(PATH_TO_DATA))\n",
    "\n",
    "loaded_model.fit_generator(image_generator, \n",
    "                    samples_per_epoch=samples, \n",
    "                    nb_epoch=10,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
