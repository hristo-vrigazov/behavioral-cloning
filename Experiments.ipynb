{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioural cloning project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure matlab to show graphics in the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change to 'data' when training on a GPU\n",
    "PATH_TO_DATA = 'data/sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shape of the image\n",
    "input_shape = (160, 320, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_folder(data_folder):\n",
    "    return '{}/IMG'.format(data_folder)\n",
    "\n",
    "def path_driving_log(data_folder):\n",
    "    return '{}/driving_log.csv'.format(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets = ['train', 'test', 'valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_driving_log_dataframe(data_folder):\n",
    "    driving_log_df = pd.read_csv(path_driving_log(data_folder))\n",
    "    return driving_log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_folders = dict(zip(datasets, map(lambda folder: '{0}/{1}'.format(PATH_TO_DATA, folder), datasets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 'data/sample/test',\n",
       " 'train': 'data/sample/train',\n",
       " 'valid': 'data/sample/valid'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import imread\n",
    "from os import listdir\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def image_label_generator(data_folder, batch_size=2):\n",
    "    driving_log_df = get_driving_log_dataframe(data_folder)\n",
    "    number_of_examples = len(driving_log_df)\n",
    "    image_columns = ['center', 'left', 'right']\n",
    "    \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    index_in_batch = 0\n",
    "    batch_number = 0\n",
    "    \n",
    "    while True:\n",
    "        for image_column in image_columns:\n",
    "            image_series = driving_log_df[image_column]\n",
    "            steering_series = driving_log_df['steering']\n",
    "            for offset in range(0, number_of_examples, batch_size):\n",
    "                X_train = []\n",
    "                y_train = []\n",
    "\n",
    "                end_of_batch = min(number_of_examples, offset + batch_size)\n",
    "\n",
    "                for j in range(offset, end_of_batch):\n",
    "                    image_filename = image_series[j].lstrip().rstrip()\n",
    "                    image = imread('{0}/{1}'.format(data_folder, image_filename))\n",
    "                    label = steering_series[j]\n",
    "                    X_train.append(image)\n",
    "                    y_train.append(label)\n",
    "                    X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "                yield np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(3, 1, 1, \n",
    "                          input_shape=input_shape, \n",
    "                          border_mode='same', \n",
    "                          activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(24, 5, 5,\n",
    "                       activation='relu',\n",
    "                       subsample=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(36, 5, 5,\n",
    "                       activation='relu',\n",
    "                       subsample=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(48, 5, 5,\n",
    "                       activation='relu',\n",
    "                       subsample=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(64, 3, 3,\n",
    "                       activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(64, 3, 3,\n",
    "                       activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(64, 3, 3,\n",
    "                       activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(64, 3, 3,\n",
    "                       activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(64, 3, 3,\n",
    "                       activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(64, 3, 3,\n",
    "                       activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(64, 3, 3,\n",
    "                       activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(64, 3, 3,\n",
    "                       activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 160, 320, 3)   12          convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 160, 320, 3)   12          convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 78, 158, 24)   1824        batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 78, 158, 24)   96          convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 37, 77, 36)    21636       batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 37, 77, 36)    144         convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 17, 37, 48)    43248       batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 17, 37, 48)    192         convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 15, 35, 64)    27712       batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 15, 35, 64)    256         convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 13, 33, 64)    36928       batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNorma (None, 13, 33, 64)    256         convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 11, 31, 64)    36928       batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_7 (BatchNorma (None, 11, 31, 64)    256         convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 9, 29, 64)     36928       batchnormalization_7[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_8 (BatchNorma (None, 9, 29, 64)     256         convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 7, 27, 64)     36928       batchnormalization_8[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_9 (BatchNorma (None, 7, 27, 64)     256         convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 5, 25, 64)     36928       batchnormalization_9[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_10 (BatchNorm (None, 5, 25, 64)     256         convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 3, 23, 64)     36928       batchnormalization_10[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_11 (BatchNorm (None, 3, 23, 64)     256         convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 1, 21, 64)     36928       batchnormalization_11[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_12 (BatchNorm (None, 1, 21, 64)     256         convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1344)          0           batchnormalization_12[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 256)           344320      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 128)           32896       dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 32)            4128        dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             33          dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 736,797\n",
      "Trainable params: 735,551\n",
      "Non-trainable params: 1,246\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='mse',\n",
    "             metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_generator = image_label_generator(path_to_folders['train'])\n",
    "valid_generator = image_label_generator(path_to_folders['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 00000: val_loss improved from inf to 0.00254, saving model to weights-improvement-00-0.00.hdf5\n",
      "2/2 [==============================] - 12s - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 2/10\n",
      "Epoch 00001: val_loss did not improve\n",
      "2/2 [==============================] - 0s - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 3/10\n",
      "Epoch 00002: val_loss did not improve\n",
      "2/2 [==============================] - 0s - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 4/10\n",
      "Epoch 00003: val_loss did not improve\n",
      "2/2 [==============================] - 0s - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 5/10\n",
      "Epoch 00004: val_loss did not improve\n",
      "2/2 [==============================] - 0s - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 6/10\n",
      "Epoch 00005: val_loss did not improve\n",
      "2/2 [==============================] - 0s - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 7/10\n",
      "Epoch 00006: val_loss did not improve\n",
      "2/2 [==============================] - 0s - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 8/10\n",
      "Epoch 00007: val_loss did not improve\n",
      "2/2 [==============================] - 0s - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 9/10\n",
      "Epoch 00008: val_loss did not improve\n",
      "2/2 [==============================] - 0s - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 10/10\n",
      "Epoch 00009: val_loss did not improve\n",
      "2/2 [==============================] - 0s - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa124dd79e8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, \n",
    "                    samples_per_epoch=2, \n",
    "                    nb_epoch=10, \n",
    "                    validation_data=valid_generator,\n",
    "                    nb_val_samples=1,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_val, y_val = next(image_label_generator(path_to_folders['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.       ],\n",
       "       [ 0.0610016]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
