{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioural cloning project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "# Configure matlab to show graphics in the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change to 'data' when training on a GPU\n",
    "PATH_TO_DATA = 'all_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shape of the image\n",
    "input_shape = (66, 200, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_folder(data_folder):\n",
    "    return '{}/IMG'.format(data_folder)\n",
    "\n",
    "def path_driving_log(data_folder):\n",
    "    return '{}/driving_log.csv'.format(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets = ['train', 'test', 'valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_driving_log_dataframe(data_folder):\n",
    "    driving_log_df = pd.read_csv(path_driving_log(data_folder))\n",
    "    return driving_log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_folders = dict(zip(datasets, map(lambda folder: '{0}/{1}'.format(PATH_TO_DATA, folder), datasets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 'all_data/test', 'train': 'all_data/train', 'valid': 'all_data/valid'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading imutils-0.3.10.tar.gz\n",
      "Building wheels for collected packages: imutils\n",
      "  Running setup.py bdist_wheel for imutils ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/carnd/.cache/pip/wheels/4c/a7/0f/2ac8bb8d2d9f472f26413454a7ae30d96cd9f645c9f526a2b9\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.3.10\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import imread\n",
    "from os import listdir\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def image_label_generator(data_folder, batch_size=64):\n",
    "    driving_log_df = get_driving_log_dataframe(data_folder)\n",
    "    number_of_examples = len(driving_log_df)\n",
    "    image_columns = ['center', 'left', 'right']\n",
    "    \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    weights = []\n",
    "    index_in_batch = 0\n",
    "    batch_number = 0\n",
    "    \n",
    "    while True:\n",
    "        for image_column in image_columns:\n",
    "            image_series = driving_log_df[image_column]\n",
    "            steering_series = driving_log_df['steering']\n",
    "            for offset in range(0, number_of_examples, batch_size):\n",
    "                X_train = []\n",
    "                y_train = []\n",
    "                weights = []\n",
    "\n",
    "                end_of_batch = min(number_of_examples, offset + batch_size)\n",
    "\n",
    "                for j in range(offset, end_of_batch):\n",
    "                    image_filename = image_series[j].lstrip().rstrip()\n",
    "                    image = Image.open('{0}/{1}'.format(data_folder, image_filename))\n",
    "                    image = np.asarray(image.resize((200, 66)))\n",
    "                    label = steering_series[j]\n",
    "                    \n",
    "#                     weights.append(1)\n",
    "                    if abs(label) < 10e-4:\n",
    "                        weights.append(1)\n",
    "                    else:\n",
    "                        if label > 0:\n",
    "                            weights.append(5)\n",
    "                        else:\n",
    "                            weights.append(3)\n",
    "                    \n",
    "                    \n",
    "                    X_train.append(image)\n",
    "                    y_train.append(label)\n",
    "                    X_train, y_train, weights = shuffle(X_train, y_train, weights)\n",
    "\n",
    "                yield np.array(X_train), np.array(y_train), np.array(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(3, 1, 1, \n",
    "                          input_shape=input_shape, \n",
    "                          border_mode='same', \n",
    "                          activation='relu',\n",
    "                          init='he_normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(24, \n",
    "                        5, 5,\n",
    "                       subsample=(2, 2),\n",
    "                       init='he_normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(36, \n",
    "                        5, 5,\n",
    "                       subsample=(2, 2),\n",
    "                       init='he_normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(48, \n",
    "                        5, 5,\n",
    "                       subsample=(2, 2),\n",
    "                       init='he_normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(64,\n",
    "                       3, 3,\n",
    "                       init='he_normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(64,\n",
    "                       3, 3,\n",
    "                       init='he_normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu', init='he_normal'))\n",
    "model.add(Dense(50, activation='relu', init='he_normal'))\n",
    "model.add(Dense(10, activation='relu', init='he_normal'))\n",
    "model.add(Dense(1, activation='linear', init='he_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_31 (Convolution2D) (None, 66, 200, 3)    12          convolution2d_input_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 66, 200, 3)    0           convolution2d_31[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_22 (BatchNorm (None, 66, 200, 3)    12          dropout_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_32 (Convolution2D) (None, 31, 98, 24)    1824        batchnormalization_22[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 31, 98, 24)    0           convolution2d_32[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_23 (BatchNorm (None, 31, 98, 24)    96          dropout_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_33 (Convolution2D) (None, 14, 47, 36)    21636       batchnormalization_23[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, 14, 47, 36)    0           convolution2d_33[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_24 (BatchNorm (None, 14, 47, 36)    144         dropout_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_34 (Convolution2D) (None, 5, 22, 48)     43248       batchnormalization_24[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)             (None, 5, 22, 48)     0           convolution2d_34[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_25 (BatchNorm (None, 5, 22, 48)     192         dropout_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_35 (Convolution2D) (None, 3, 20, 64)     27712       batchnormalization_25[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)             (None, 3, 20, 64)     0           convolution2d_35[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_26 (BatchNorm (None, 3, 20, 64)     256         dropout_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_36 (Convolution2D) (None, 1, 18, 64)     36928       batchnormalization_26[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)             (None, 1, 18, 64)     0           convolution2d_36[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 1152)          0           dropout_19[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_21 (Dense)                 (None, 100)           115300      flatten_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_22 (Dense)                 (None, 50)            5050        dense_21[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_23 (Dense)                 (None, 10)            510         dense_22[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_24 (Dense)                 (None, 1)             11          dense_23[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 252,931\n",
      "Trainable params: 252,581\n",
      "Non-trainable params: 350\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=10e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam, \n",
    "              loss='mse',\n",
    "             metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_generator = image_label_generator(PATH_TO_DATA)\n",
    "samples = len(get_driving_log_dataframe(PATH_TO_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "14816/14816 [==============================] - 51s - loss: 0.1689 - mean_squared_error: 0.0575    \n",
      "Epoch 2/18\n",
      "14816/14816 [==============================] - 48s - loss: 0.1218 - mean_squared_error: 0.0346    \n",
      "Epoch 3/18\n",
      "14816/14816 [==============================] - 48s - loss: 0.1153 - mean_squared_error: 0.0312    \n",
      "Epoch 4/18\n",
      "14816/14816 [==============================] - 48s - loss: 0.1124 - mean_squared_error: 0.0302    \n",
      "Epoch 5/18\n",
      "14816/14816 [==============================] - 48s - loss: 0.1098 - mean_squared_error: 0.0303    \n",
      "Epoch 6/18\n",
      "14816/14816 [==============================] - 48s - loss: 0.0981 - mean_squared_error: 0.0277    \n",
      "Epoch 7/18\n",
      "14816/14816 [==============================] - 48s - loss: 0.0902 - mean_squared_error: 0.0264    \n",
      "Epoch 8/18\n",
      "14816/14816 [==============================] - 48s - loss: 0.0829 - mean_squared_error: 0.0255    \n",
      "Epoch 9/18\n",
      "14816/14816 [==============================] - 48s - loss: 0.0780 - mean_squared_error: 0.0249    \n",
      "Epoch 10/18\n",
      "14816/14816 [==============================] - 48s - loss: 0.0763 - mean_squared_error: 0.0249    \n",
      "Epoch 11/18\n",
      "14816/14816 [==============================] - 48s - loss: 0.0762 - mean_squared_error: 0.0253    \n",
      "Epoch 12/18\n",
      "14816/14816 [==============================] - 48s - loss: 0.0722 - mean_squared_error: 0.0236    \n",
      "Epoch 13/18\n",
      "14816/14816 [==============================] - 48s - loss: 0.0790 - mean_squared_error: 0.0269    \n",
      "Epoch 14/18\n",
      "14816/14816 [==============================] - 48s - loss: 0.0753 - mean_squared_error: 0.0253    \n",
      "Epoch 15/18\n",
      "14816/14816 [==============================] - 48s - loss: 0.0735 - mean_squared_error: 0.0243    \n",
      "Epoch 16/18\n",
      "14816/14816 [==============================] - 48s - loss: 0.0708 - mean_squared_error: 0.0239    \n",
      "Epoch 17/18\n",
      "14816/14816 [==============================] - 48s - loss: 0.0691 - mean_squared_error: 0.0233    \n",
      "Epoch 18/18\n",
      "14816/14816 [==============================] - 48s - loss: 0.0674 - mean_squared_error: 0.0230    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efdf2712898>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(image_generator, \n",
    "                    samples_per_epoch=samples, \n",
    "                    nb_epoch=18,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_val, y_val, w = next(image_label_generator(PATH_TO_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08967546],\n",
       "       [-0.06616151],\n",
       "       [-0.10278946],\n",
       "       [-0.09259585],\n",
       "       [-0.10940063],\n",
       "       [-0.10381505],\n",
       "       [-0.06627685],\n",
       "       [ 0.18588325],\n",
       "       [-0.08025751],\n",
       "       [-0.10272971],\n",
       "       [-0.08930337],\n",
       "       [-0.11079952],\n",
       "       [-0.15881106],\n",
       "       [-0.13396287],\n",
       "       [-0.0843271 ],\n",
       "       [-0.07536602],\n",
       "       [-0.19298965],\n",
       "       [-0.03857133],\n",
       "       [-0.1059418 ],\n",
       "       [-0.11409095],\n",
       "       [-0.10841718],\n",
       "       [ 0.18588325],\n",
       "       [-0.14776227],\n",
       "       [-0.11993295],\n",
       "       [-0.17805156],\n",
       "       [ 0.18588325],\n",
       "       [-0.07372436],\n",
       "       [-0.08802262],\n",
       "       [-0.06658542],\n",
       "       [-0.18182668],\n",
       "       [-0.11287931],\n",
       "       [-0.14715546],\n",
       "       [-0.09928486],\n",
       "       [-0.06285028],\n",
       "       [-0.15824306],\n",
       "       [-0.15553769],\n",
       "       [-0.14736149],\n",
       "       [ 0.18588325],\n",
       "       [-0.18080536],\n",
       "       [-0.09366712],\n",
       "       [-0.09812418],\n",
       "       [-0.11197266],\n",
       "       [-0.11008781],\n",
       "       [-0.16207066],\n",
       "       [-0.09614736],\n",
       "       [ 0.18588325],\n",
       "       [-0.11848766],\n",
       "       [-0.07362676],\n",
       "       [-0.09660372],\n",
       "       [ 0.18588325],\n",
       "       [-0.04019406],\n",
       "       [-0.11367932],\n",
       "       [-0.06913954],\n",
       "       [-0.1416848 ],\n",
       "       [-0.10266644],\n",
       "       [-0.04864043],\n",
       "       [-0.10956499],\n",
       "       [-0.11104137],\n",
       "       [-0.04332367],\n",
       "       [-0.11228395],\n",
       "       [-0.0734058 ],\n",
       "       [-0.11041316],\n",
       "       [-0.05806197],\n",
       "       [-0.05359375]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04076847, -0.1167233 ,  0.07132844,  0.        ,  0.07132844,\n",
       "       -0.05975719,  0.        ,  0.        ,  0.1670138 , -0.09773462,\n",
       "       -0.05975719,  0.0617599 ,  0.0617599 ,  0.1670138 ,  0.1670138 ,\n",
       "        0.01391724,  0.        ,  0.0617599 ,  0.07132844])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
