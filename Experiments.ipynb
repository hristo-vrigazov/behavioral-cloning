{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioural cloning project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Configure matlab to show graphics in the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change to 'data' when training on a GPU\n",
    "PATH_TO_DATA = 'data/sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shape of the image\n",
    "input_shape = (66, 200, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_folder(data_folder):\n",
    "    return '{}/IMG'.format(data_folder)\n",
    "\n",
    "def path_driving_log(data_folder):\n",
    "    return '{}/driving_log.csv'.format(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets = ['train', 'test', 'valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_driving_log_dataframe(data_folder):\n",
    "    driving_log_df = pd.read_csv(path_driving_log(data_folder))\n",
    "    return driving_log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_folders = dict(zip(datasets, map(lambda folder: '{0}/{1}'.format(PATH_TO_DATA, folder), datasets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 'data/sample/test',\n",
       " 'train': 'data/sample/train',\n",
       " 'valid': 'data/sample/valid'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in /home/hvrigazov/anaconda2/envs/carnd-term1/lib/python3.5/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import imread\n",
    "from os import listdir\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def image_label_generator(data_folder, batch_size=64):\n",
    "    driving_log_df = get_driving_log_dataframe(data_folder)\n",
    "    number_of_examples = len(driving_log_df)\n",
    "    image_columns = ['center', 'left', 'right']\n",
    "    \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    weights = []\n",
    "    index_in_batch = 0\n",
    "    batch_number = 0\n",
    "    \n",
    "    while True:\n",
    "        for image_column in image_columns:\n",
    "            image_series = driving_log_df[image_column]\n",
    "            steering_series = driving_log_df['steering']\n",
    "            for offset in range(0, number_of_examples, batch_size):\n",
    "                X_train = []\n",
    "                y_train = []\n",
    "                weights = []\n",
    "\n",
    "                end_of_batch = min(number_of_examples, offset + batch_size)\n",
    "\n",
    "                for j in range(offset, end_of_batch):\n",
    "                    image_filename = image_series[j].lstrip().rstrip()\n",
    "                    image = Image.open('{0}/{1}'.format(data_folder, image_filename))\n",
    "                    image = np.asarray(image.resize((200, 66)))\n",
    "                    label = steering_series[j]\n",
    "                    \n",
    "                    if abs(label) < 10e-4:\n",
    "                        weights.append(1)\n",
    "                    else:\n",
    "                        weights.append(10)\n",
    "                    \n",
    "                    X_train.append(image)\n",
    "                    y_train.append(label)\n",
    "                    X_train, y_train, weights = shuffle(X_train, y_train, weights)\n",
    "\n",
    "                yield np.array(X_train), np.array(y_train), np.array(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(3, 1, 1, \n",
    "                          input_shape=input_shape, \n",
    "                          border_mode='same', \n",
    "                          activation='relu',\n",
    "                          init='he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(24, \n",
    "                        5, 5,\n",
    "                       subsample=(2, 2),\n",
    "                       init='he_normal'))\n",
    "model.add(Convolution2D(36, \n",
    "                        5, 5,\n",
    "                       subsample=(2, 2),\n",
    "                       init='he_normal'))\n",
    "model.add(Convolution2D(48, \n",
    "                        5, 5,\n",
    "                       subsample=(2, 2),\n",
    "                       init='he_normal'))\n",
    "model.add(Convolution2D(64,\n",
    "                       3, 3,\n",
    "                       init='he_normal'))\n",
    "model.add(Convolution2D(64,\n",
    "                       3, 3,\n",
    "                       init='he_normal'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu', init='he_normal'))\n",
    "model.add(Dense(50, activation='relu', init='he_normal'))\n",
    "model.add(Dense(10, activation='relu', init='he_normal'))\n",
    "model.add(Dense(1, activation='linear', init='he_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 66, 200, 3)    12          convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 66, 200, 3)    12          convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 31, 98, 24)    1824        batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 14, 47, 36)    21636       convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 5, 22, 48)     43248       convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 3, 20, 64)     27712       convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 1, 18, 64)     36928       convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1152)          0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           115300      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 50)            5050        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            510         dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             11          dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 252,243\n",
      "Trainable params: 252,237\n",
      "Non-trainable params: 6\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=10e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam, \n",
    "              loss='mse',\n",
    "             metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_generator = image_label_generator(PATH_TO_DATA)\n",
    "validation_generator = image_label_generator(path_to_folders['valid'])\n",
    "samples = len(get_driving_log_dataframe(PATH_TO_DATA))\n",
    "nb_val_samples = len(get_driving_log_dataframe(path_to_folders['valid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 0s - loss: 5.5258 - mean_squared_error: 0.6412\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 0s - loss: 4.6247 - mean_squared_error: 0.8633\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 0s - loss: 22.0791 - mean_squared_error: 2.6391\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 0s - loss: 21.7424 - mean_squared_error: 2.5774\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 0s - loss: 21.5573 - mean_squared_error: 2.6387\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 0s - loss: 45.1753 - mean_squared_error: 5.3576\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 0s - loss: 45.1275 - mean_squared_error: 5.4549\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 0s - loss: 44.4413 - mean_squared_error: 5.2160\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 0s - loss: 63.6388 - mean_squared_error: 7.5040\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 0s - loss: 61.3393 - mean_squared_error: 7.6078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f21fc3dcd30>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(image_generator, \n",
    "                    samples_per_epoch=samples, \n",
    "                    nb_epoch=10,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_val, y_val, w = next(image_label_generator(PATH_TO_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.69347763],\n",
       "       [ 47.21813202],\n",
       "       [  8.31283951],\n",
       "       [  5.42915535],\n",
       "       [ 12.9414835 ],\n",
       "       [ 12.13756371],\n",
       "       [ 41.34660721],\n",
       "       [ 11.77419376],\n",
       "       [ 11.03258514],\n",
       "       [ 49.16252518],\n",
       "       [  9.37642574],\n",
       "       [  8.07772827],\n",
       "       [  8.46710205],\n",
       "       [  8.12908363],\n",
       "       [ 11.30315876],\n",
       "       [ 11.1290493 ],\n",
       "       [ 44.84928513],\n",
       "       [  5.59077358],\n",
       "       [ 13.10061836]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04076847, -0.1167233 ,  0.07132844,  0.        ,  0.07132844,\n",
       "       -0.05975719,  0.        ,  0.        ,  0.1670138 , -0.09773462,\n",
       "       -0.05975719,  0.0617599 ,  0.0617599 ,  0.1670138 ,  0.1670138 ,\n",
       "        0.01391724,  0.        ,  0.0617599 ,  0.07132844])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
