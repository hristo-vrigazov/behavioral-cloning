{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioural cloning project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Configure matlab to show graphics in the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change to 'data' when training on a GPU\n",
    "PATH_TO_DATA = 'data/sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shape of the image\n",
    "input_shape = (160, 320, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_folder(data_folder):\n",
    "    return '{}/IMG'.format(data_folder)\n",
    "\n",
    "def path_driving_log(data_folder):\n",
    "    return '{}/driving_log.csv'.format(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets = ['train', 'test', 'valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_driving_log_dataframe(data_folder):\n",
    "    driving_log_df = pd.read_csv(path_driving_log(data_folder))\n",
    "    return driving_log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_folders = dict(zip(datasets, map(lambda folder: '{0}/{1}'.format(PATH_TO_DATA, folder), datasets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 'data/sample/test',\n",
       " 'train': 'data/sample/train',\n",
       " 'valid': 'data/sample/valid'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import imread\n",
    "from os import listdir\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def image_label_generator(data_folder, batch_size=64):\n",
    "    driving_log_df = get_driving_log_dataframe(data_folder)\n",
    "    number_of_examples = len(driving_log_df)\n",
    "    image_columns = ['center', 'left', 'right']\n",
    "    \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    weights = []\n",
    "    index_in_batch = 0\n",
    "    batch_number = 0\n",
    "    \n",
    "    while True:\n",
    "        for image_column in image_columns:\n",
    "            image_series = driving_log_df[image_column]\n",
    "            steering_series = driving_log_df['steering']\n",
    "            for offset in range(0, number_of_examples, batch_size):\n",
    "                X_train = []\n",
    "                y_train = []\n",
    "                weights = []\n",
    "\n",
    "                end_of_batch = min(number_of_examples, offset + batch_size)\n",
    "\n",
    "                for j in range(offset, end_of_batch):\n",
    "                    image_filename = image_series[j].lstrip().rstrip()\n",
    "                    image = imread('{0}/{1}'.format(data_folder, image_filename))\n",
    "                    label = steering_series[j]\n",
    "                    \n",
    "                    if abs(label) < 0.2:\n",
    "                        weights.append(1)\n",
    "                    else:\n",
    "                        weights.append(100)\n",
    "                    \n",
    "                    X_train.append(image)\n",
    "                    y_train.append(label)\n",
    "                    X_train, y_train, weights = shuffle(X_train, y_train, weights)\n",
    "\n",
    "                yield np.array(X_train), np.array(y_train), np.array(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(3, 1, 1, \n",
    "                          input_shape=input_shape, \n",
    "                          border_mode='same', \n",
    "                          activation='relu'))\n",
    "model.add(Convolution2D(24, 5, 5,\n",
    "                       activation='relu',\n",
    "                       subsample=(2, 2)))\n",
    "model.add(Convolution2D(36, 5, 5,\n",
    "                       activation='relu',\n",
    "                       subsample=(2, 2)))\n",
    "model.add(Convolution2D(48, 5, 5,\n",
    "                       activation='relu',\n",
    "                       subsample=(2, 2)))\n",
    "model.add(Convolution2D(64, 3, 3,\n",
    "                       activation='relu'))\n",
    "model.add(Convolution2D(80, 3, 3,\n",
    "                       activation='relu'))\n",
    "model.add(Convolution2D(96, 3, 3,\n",
    "                       activation='relu'))\n",
    "model.add(Convolution2D(112, 3, 3,\n",
    "                       activation='relu'))\n",
    "model.add(Convolution2D(128, 3, 3,\n",
    "                       activation='relu'))\n",
    "model.add(Convolution2D(144, 3, 3,\n",
    "                       activation='relu'))\n",
    "model.add(Convolution2D(160, 3, 3,\n",
    "                       activation='relu'))\n",
    "model.add(Convolution2D(176, 3, 3,\n",
    "                       activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_14 (Convolution2D) (None, 160, 320, 3)   12          convolution2d_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 78, 158, 24)   1824        convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_16 (Convolution2D) (None, 37, 77, 36)    21636       convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_17 (Convolution2D) (None, 17, 37, 48)    43248       convolution2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D) (None, 15, 35, 64)    27712       convolution2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_19 (Convolution2D) (None, 13, 33, 80)    46160       convolution2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_20 (Convolution2D) (None, 11, 31, 96)    69216       convolution2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_21 (Convolution2D) (None, 9, 29, 112)    96880       convolution2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_22 (Convolution2D) (None, 7, 27, 128)    129152      convolution2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_23 (Convolution2D) (None, 5, 25, 144)    166032      convolution2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_24 (Convolution2D) (None, 3, 23, 160)    207520      convolution2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_25 (Convolution2D) (None, 1, 21, 176)    253616      convolution2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 3696)          0           convolution2d_25[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 256)           946432      flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 128)           32896       dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 32)            4128        dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 1)             33          dense_7[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 2,046,497\n",
      "Trainable params: 2,046,497\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam, \n",
    "              loss='mse',\n",
    "             metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_generator = image_label_generator(path_to_folders['train'])\n",
    "valid_generator = image_label_generator(path_to_folders['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "number_of_training_examples = len(get_driving_log_dataframe(path_to_folders['train']) * 3)\n",
    "number_of_validation_examples = len(get_driving_log_dataframe(path_to_folders['valid']) * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 00000: loss improved from inf to 0.01025, saving model to weights-improvement-00-0.00.hdf5\n",
      "12/12 [==============================] - 3s - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 2/10\n",
      "Epoch 00001: loss improved from 0.01025 to 0.01015, saving model to weights-improvement-01-0.00.hdf5\n",
      "12/12 [==============================] - 1s - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 3/10\n",
      "Epoch 00002: loss improved from 0.01015 to 0.01000, saving model to weights-improvement-02-0.00.hdf5\n",
      "12/12 [==============================] - 1s - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 4/10\n",
      "Epoch 00003: loss improved from 0.01000 to 0.00977, saving model to weights-improvement-03-0.00.hdf5\n",
      "12/12 [==============================] - 1s - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 5/10\n",
      "Epoch 00004: loss improved from 0.00977 to 0.00950, saving model to weights-improvement-04-0.00.hdf5\n",
      "12/12 [==============================] - 1s - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 6/10\n",
      "Epoch 00005: loss improved from 0.00950 to 0.00928, saving model to weights-improvement-05-0.00.hdf5\n",
      "12/12 [==============================] - 1s - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 7/10\n",
      "Epoch 00006: loss improved from 0.00928 to 0.00903, saving model to weights-improvement-06-0.00.hdf5\n",
      "12/12 [==============================] - 1s - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 8/10\n",
      "Epoch 00007: loss improved from 0.00903 to 0.00897, saving model to weights-improvement-07-0.00.hdf5\n",
      "12/12 [==============================] - 1s - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 9/10\n",
      "Epoch 00008: loss did not improve\n",
      "12/12 [==============================] - 1s - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 10/10\n",
      "Epoch 00009: loss did not improve\n",
      "12/12 [==============================] - 1s - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc7eefea0b8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, \n",
    "                    samples_per_epoch=number_of_training_examples, \n",
    "                    nb_epoch=10, \n",
    "                    validation_data=valid_generator,\n",
    "                    nb_val_samples=number_of_validation_examples,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_val, y_val, w = next(image_label_generator(path_to_folders['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04763204],\n",
       "       [ 0.04611243],\n",
       "       [ 0.04542437],\n",
       "       [ 0.04617226],\n",
       "       [ 0.04782542],\n",
       "       [ 0.04927502],\n",
       "       [ 0.05671517],\n",
       "       [ 0.0418238 ],\n",
       "       [ 0.04216757],\n",
       "       [ 0.0431305 ],\n",
       "       [ 0.04857197],\n",
       "       [ 0.04199147]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.09773462,  0.07132844,  0.0617599 ,  0.1670138 ,  0.        ,\n",
       "        0.        ,  0.0617599 , -0.1167233 , -0.05975719,  0.1670138 ,\n",
       "        0.        ,  0.1670138 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
